{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Equilibrium Nets for Guvenen (2009)\n",
    "\n",
    "#### By  Matias Covarrubias and Min Fang\n",
    "\n",
    "In this notebook, we use `TensorFlow` to solve [Guvenen (2009)](http://users.econ.umn.edu/~guvenen/HABHET2008.pdf) with _deep equilibrium nets_ method by [Azinovic, Gaegauf, & Scheidegger (2020)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3393482).\n",
    "\n",
    "\n",
    "## The model <a id='model'></a>\n",
    "\n",
    "GDSGE offers a good [summary](http://www.gdsge.com/example/Guvenen2009/Guvenen2009.html).\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "0. [Set up workspace](#workspace)\n",
    "1. [Model calibration](#modelcal)\n",
    "2. [_Deep equilibrium net_ hyper-parameters](#deqnparam)\n",
    "    1. [Neural network](#nn)\n",
    "3. [Economic model](#econmodel)\n",
    "    1. [Current period (t)](#currentperiod)\n",
    "    2. [Next period (t+1)](#nextperiod)\n",
    "    3. [Cost/Euler function](#cost)\n",
    "4. [Training](#training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up workspace <a id='workspace'></a>\n",
    "\n",
    "First, we need to set up the workspace. All of the packages are standard python packages. This version of the _deep equilibrium net_ notebook will be computed with `TensorFlow 2`. Make sure you are working in an environment with TF2 installed.\n",
    "\n",
    "The only special module is `utils` from which we import a mini-batch function `random_mini_batches` and a function that initializes the neural network weights `initialize_nn_weight`.\n",
    "\n",
    "### Saving and continuing training\n",
    "\n",
    "You can save and resume training by saving and loading the tensorflow session and data starting point.\n",
    "* The saved session stores the neural network weights and the optimizer's state. If you have saved a session that you would like to reload, set `sess_path` to the session checkpoint path. For example, to load the 100th episode's session set `sess_path = './output/sess_100.ckpt'`. Otherwise, set `sess_path` to `None` to train from scratch. Currently, this script saves the session at the end of each [episode](#deqnparam).\n",
    "* The saved data starting point stores the an exogeneous shock and a capital distribution, which can be used to simulate states into the future from. If you have saved a starting point that you would like to reload, set `data_path` to the numpy data path. For example, to load the 100th episode's starting point set `data_path = './output/data_100.npy'`. Otherwise, set `data_path` to `None` to train from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('tf version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Import modules\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from utils import initialize_nn_weight, random_mini_batches\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rc('xtick', labelsize='small')\n",
    "plt.rc('ytick', labelsize='small')\n",
    "std_figsize = (4, 4)\n",
    "\n",
    "# Set the seed for replicable results\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed) # was \"tf.set_random_seed(seed)\" in tf1\n",
    "\n",
    "# Helper variables\n",
    "eps = 0.00001  # Small epsilon value\n",
    "\n",
    "# Make output directory to save network weights and starting point\n",
    "if not os.path.exists('./output'):\n",
    "    os.mkdir('./output')\n",
    "\n",
    "# Path to saved tensorflow session\n",
    "sess_path = None\n",
    "# Path to saved data starting point\n",
    "data_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model calibration <a id='modelcal'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "alpha = 6\n",
    "alpha_tf = tf.constant(alpha)\n",
    "beta = 0.9966\n",
    "beta_tf = tf.constant(beta)\n",
    "theta = 0.3\n",
    "theta_tf = tf.constant(theta)\n",
    "rho_h = 1/0.3\n",
    "tho_h_tf = tf.constant(rho_h)\n",
    "rho_n = 1/0.1\n",
    "rho_n_tf = tf.constant(rho_n)\n",
    "delta = 0.0066\n",
    "delta_tf = tf.constant(delta)\n",
    "mu = 0.2\n",
    "mu_tf = tf.constant(mu)\n",
    "phi_k = 0.4\n",
    "phi_k_tf = tf.constant(phi_k)\n",
    "chi = 0.005\n",
    "chi_tf = tf.constant(phi_k)\n",
    "Kbar = ((1/beta - 1 + delta)/theta)**(1/(theta-1))\n",
    "Bbar = -0.1*(1-theta)*Kbar**theta\n",
    "Kbar_tf = tf.constant(Kbar)\n",
    "Bbar_tf = tf.constant(Bbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exodogeneous TFP shock\n",
    "import quantecon\n",
    "phi_z = 0.95\n",
    "sigma_z = 0.05\n",
    "x = quantecon.tauchen(phi_z,sigma_z,n=3)\n",
    "Pi = x.P\n",
    "Zgrid = np.exp(x.state_values)\n",
    "Pi_tf = tf.constant(Pi, dtype=tf.float32)\n",
    "Zgrid_tf = tf.constant(Zgrid, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ！TF2 is very different here\n",
    "\n",
    "We would use Model subclassing:\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. _Deep equilibrium net_ hyper-parameters <a id='deqnparam'></a>\n",
    "\n",
    "Here, we will briefly outline the _deep equilibrium net_ architecture and choice of hyper-parameters. By hyper-parameters, we refer too all of the parameters that can be chosen freely by the modeller. This is in contrast to \"parameters\", which refers to the neural network weights that are learned during training.\n",
    "We found it helpful to augment the state we pass to the neural network with redundant information, such as aggregate variables and the distribution of financial wealth.\n",
    "In this notebook, we do the same.\n",
    "\n",
    "  * Neural network architecture (see NN diagram below):\n",
    "    * The neural network takes an extended state that is 32-dimensional:\n",
    "        * Natural state:\n",
    "            * 1 dimension for the shock index,\n",
    "            * 1 dimension for aggregate capital\n",
    "            * 1 dimension for bond position\n",
    "        * Redundant extension: (do we need this?)\n",
    "            * 1 dimension for the current TFP,\n",
    "            * 1 dimension for the current depreciation,\n",
    "            * 1 dimension for aggregate capital,\n",
    "            * 1 dimension for aggregate labor supply, \n",
    "            * 1 dimension for the return on capital,\n",
    "            * 1 dimension for the wage,\n",
    "            * 1 dimension for the aggregate production,\n",
    "            * 6 dimensions for the distribution of financial wealth,\n",
    "            * 6 dimensions for the distribution of labor income, \n",
    "            * 6 dimensions for the distribution of total income.\n",
    "    * The first and second hidden layers have 100 and 50 nodes, respectively.\n",
    "    * The output layer is 5-dimensional.\n",
    "  * Training hyper-parameters:\n",
    "    * We simulate 5'000 episodes.*\n",
    "    * Per episode, we compute 20 epochs.\n",
    "    * We use a minibatch size of 512.\n",
    "    * Each episode is 10'240 periods long.\n",
    "    * The learning rate is set to 0.00001.\n",
    "\n",
    "\\* In the _deep equilibrium net_ framework we iterate between a simulation and training phase (see [training](#training)). We first simulate a training dataset based on the current state of the neural network. That is, we simulate a random sequence of exogenous shocks for which we compute the capital holdings of the agents. We call the set of simulated periods an _episode_. 5'000 episodes means that we re-simulate the training data 5'000 times.\n",
    "\n",
    "Note that this calibration is not optimal for the economic model being solved. This script is intended to provide a simple introduction to _deep equilibrium nets_ and not an indepth discussion on optimizing the performance.\n",
    "\n",
    "<img src='analytic_NN1.png' style=\"width:1000px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 5000 \n",
    "len_episodes = 10240\n",
    "epochs_per_episode = 20 \n",
    "minibatch_size = 512\n",
    "num_minibatches = int(len_episodes / minibatch_size)\n",
    "lr = 0.00001\n",
    "\n",
    "# Neural network architecture parameters\n",
    "num_input_nodes = 3  # Dimension of extended state space\n",
    "num_hidden_nodes = [100, 50]  # Dimension of hidden layers\n",
    "num_output_nodes = 17  # Output dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.A. Neural network <a id='nn'></a>\n",
    "\n",
    "Since we are using a neural network with 2 hidden layers, the network maps:\n",
    "$$X \\rightarrow \\mathcal{N}(X) = \\sigma(\\sigma(XW_1 + b_1)W_2 + b_2)W_3 + b_3$$\n",
    "where $\\sigma$ is the rectified linear unit (ReLU) activation function and the output layer is activated with the linear function (which is the identity function and hence omitted from the equation). Therefore, we need 3 weight matrices $\\{W_1, W_2, W_3\\}$ and 3 bias vectors $\\{b_1, b_2, b_3\\}$ (compare with the neural network diagram above). In total, we train $300+5000+850+167$ parameters:\n",
    "\n",
    "| $W_1$ | $3 \\times 100$  | $= 300$ |\n",
    "| --- | --- | --- |\n",
    "| $W_2$ | $100 \\times 50$ | $= 5000$ |\n",
    "| $W_3$ | $50 \\times 17$ | $= 850$ |\n",
    "| $b_1 + b_2 + b_3$ | $100 + 50 + 17$ | $= 167$|\n",
    "\n",
    "\n",
    "We initialize the neural network parameters with the  `initialize_nn_weight` helper function from `utils`.\n",
    "\n",
    "Then, we compute the neural network prediction using the parameters in `nn_predict`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-13ffe8dfd0d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We create a placeholder for X, the input data for the neural network, which corresponds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# to the state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_input_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get number samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# We create a placeholder for X, the input data for the neural network, which corresponds\n",
    "# to the state.\n",
    "X = tf.placeholder(tf.float32, shape=(None, num_input_nodes))\n",
    "# Get number samples\n",
    "m = tf.shape(X)[0]\n",
    "\n",
    "# We create all of the neural network weights and biases. The weights are matrices that\n",
    "# connect the layers of the neural network. For example, W1 connects the input layer to\n",
    "# the first hidden layer\n",
    "W1 = initialize_nn_weight([num_input_nodes, num_hidden_nodes[0]])\n",
    "W2 = initialize_nn_weight([num_hidden_nodes[0], num_hidden_nodes[1]])\n",
    "W3 = initialize_nn_weight([num_hidden_nodes[1], num_output_nodes])\n",
    "\n",
    "# The biases are extra (shift) terms that are added to each node in the neural network.\n",
    "b1 = initialize_nn_weight([num_hidden_nodes[0]])\n",
    "b2 = initialize_nn_weight([num_hidden_nodes[1]])\n",
    "b3 = initialize_nn_weight([num_output_nodes])\n",
    "\n",
    "# Then, we create a function, to which we pass X, that generates a prediction based on\n",
    "# the current neural network weights. Note that the hidden layers are ReLU activated.\n",
    "# The output layer is not activated (i.e., it is activated with the linear function).\n",
    "def nn_predict(X):\n",
    "    hidden_layer1 = tf.nn.relu(tf.add(tf.matmul(X, W1), b1))\n",
    "    hidden_layer2 = tf.nn.relu(tf.add(tf.matmul(hidden_layer1, W2), b2))\n",
    "    output_layer = tf.add(tf.matmul(hidden_layer2, W3), b3)\n",
    "    return output_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Economic model <a id='econmodel'></a>\n",
    "\n",
    "In this section, we implement the economics outlined in [the model](#model).\n",
    "\n",
    "Each period, based on the current distribution of capital and the exogenous state, agents decide whether and how much to save in risky capital and to consume. Their savings together with the labor supplied implies the rest of the economic state (e.g., capital return, wages, incomes, ...). We use the neural network to generate the savings based on the agents' capital holdings at the beginning of the period. The remaining economic state is computed using the equations outlined [above](#model). The economic mechanisms are encoded in helper functions. We create one for the `firm`, the `shocks`, and `wealth` (see cell below).\n",
    "\n",
    "Then, in the face of future uncertainty, the agents again decide whether and how much to save in risky capital for the next period. We use the neural network to generate new savings for each of the future states (one for each shock). The input state for these network predictions is the next period's capital holding which are current periods savings.\n",
    "\n",
    "First, we define the helper functions for the `firm`, the `shocks`, and `wealth`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"        TO DO: replace by these\n",
    "          Y = Z*(K^theta);              % output\n",
    "  W = (1-theta)*Z*(K^theta);    % Wage = F_l\n",
    "  Div = Y - W - Inv - (1-Pf)*chi*Kss;            % dividends\n",
    "   b_h = (1-bn_shr)*chi*Kss/mu;\n",
    "  b_n = bn_shr*chi*Kss/(1-mu);\"\"\"\n",
    "\n",
    "def firm(K, eta, alpha, delta):\n",
    "    \"\"\"Calculate return, wage and aggregate production.\n",
    "    \n",
    "    r = eta * K^(alpha-1) * L^(1-alpha) + (1-delta)\n",
    "    w = eta * K^(alpha) * L^(-alpha)\n",
    "    Y = eta * K^(alpha) * L^(1-alpha) + (1-delta) * K \n",
    "\n",
    "    Args:\n",
    "        K: aggregate capital,\n",
    "        eta: TFP value,\n",
    "        alpha: output elasticity,\n",
    "        delta: depreciation value.\n",
    "\n",
    "    Returns:\n",
    "        return: return (marginal product of capital), \n",
    "        wage: wage (marginal product of labor).\n",
    "        Y: aggregate production.\n",
    "    \"\"\"\n",
    "    L = tf.ones_like(K)\n",
    "\n",
    "    r = alpha * eta * K**(alpha - 1) * L**(1 - alpha) + (1 - delta)\n",
    "    w = (1 - alpha) * eta * K**alpha * L**(-alpha)\n",
    "    Y = eta * K**alpha * L**(1 - alpha) + (1 - delta) * K\n",
    "\n",
    "    return r, w, Y\n",
    "\n",
    "def shocks(z, eta, delta):\n",
    "    \"\"\"Calculates tfp and depreciation based on current exogenous shock.\n",
    "\n",
    "    Args:\n",
    "        z: current exogenous shock (in {1, 2, 3, 4}),\n",
    "        eta: tensor of TFP values to sample from,\n",
    "        delta: tensor of depreciation values to sample from.\n",
    "\n",
    "    Returns:\n",
    "        tfp: TFP value of exogenous shock, \n",
    "        depreciation: depreciation values of exogenous shock.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    tfp = tf.gather(eta, tf.cast(z, tf.int32))\n",
    "    depreciation = tf.gather(delta, tf.cast(z, tf.int32))\n",
    "    return tfp, depreciation\n",
    "    \n",
    "def wealth(k, R, l, W):\n",
    "    \"\"\"Calculates the wealth of the agents.\n",
    "\n",
    "    Args:\n",
    "        k: capital distribution,\n",
    "        R: matrix of return,\n",
    "        l: labor distribution,\n",
    "        W: matrix of wages.\n",
    "\n",
    "    Returns:\n",
    "        fin_wealth: financial wealth distribution,\n",
    "        lab_wealth: labor income distribution,\n",
    "        tot_income: total income distribution.\n",
    "    \"\"\"\n",
    "    fin_wealth = k * R\n",
    "    lab_wealth = l * W\n",
    "    tot_income = tf.add(fin_wealth, lab_wealth)\n",
    "    return fin_wealth, lab_wealth, tot_income\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.A. Current period (t) <a id='currentperiod'></a>\n",
    "Using the current state `X` we can calculate the economy. The state is composed of today's shock ($z_t$) and today's capital ($k_t^h$). Note that this constitutes the minimal state. Often, including redundant variables is a simple way to increase the speed of convergence (see the [working paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3393482) for more information on this). However, this notebook attempts to present the most basic example for simplicity.\n",
    "\n",
    "Using the current state `X`, we predict how much the agents save ($a_t^h$) based on their current capital holdings ($k_t^h$). We do this by passing the state `X` to the neural network.\n",
    "\n",
    "Then we can calculate the agents' consumptions. To do this, we need to calculate the aggregate capital ($K_t$), the return on capital payed by the firm ($r_t$), and the wages payed by the firm ($w_t$). \n",
    "$$K_t = \\sum_{h=0}^{A-1} k_t^h,$$\n",
    "$$r_t = \\alpha \\eta_t K_t^{\\alpha - 1} L_t^{1 - \\alpha} + (1 - \\delta_t),$$\n",
    "$$w_t = (1 - \\alpha) \\eta_t K_t^{\\alpha} L_t^{-\\alpha}.$$\n",
    "\n",
    "Aggregate labor $L_t$ is always 1 by construction. Then, we can calculate each agent's total income. Finally, we calculate the resulting consumption ($c_t^h$):\n",
    "$$c_{t}^{h} = r_t k_t^h + w_t l^h_t - a_t^{h}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"To do: input states Z K bn_shr \"\"\"\n",
    "\n",
    "# Today's extended state: \n",
    "z = X[:, 0]  # exogenous shock\n",
    "tfp = X[:, 1]  # total factor productivity\n",
    "depr = X[:, 2]  # depreciation\n",
    "K = X[:, 3]  # aggregate capital\n",
    "L = X[:, 4]  # aggregate labor\n",
    "r = X[:, 5]  # return on capital\n",
    "w = X[:, 6]  # wage\n",
    "Y = X[:, 7]  # aggregate production\n",
    "k = X[:, 8 : 8 + A]  # distribution of capital\n",
    "fw = X[:, 8 + A : 8 + 2 * A]  # distribution of financial wealth\n",
    "linc = X[:, 8 + 2 * A : 8 + 3 * A]  # distribution of labor income\n",
    "inc = X[:, 8 + 3 * A : 8 + 4 * A]   # distribution of total income\n",
    "\n",
    "\"\"\" TO DO:\n",
    "policy functions c_h c_n Ps Pf Inv bn_shr_next lambdah lambdan;\"\"\"\n",
    "# Today's assets: How much the agents save\n",
    "# Get today's assets by executing the neural network\n",
    "a = nn_predict(X)\n",
    "# The last agent consumes everything they own\n",
    "a_all = tf.concat([a, tf.zeros([m, 1])], axis=1)\n",
    "\n",
    "# c_orig: the original consumption predicted by the neural network However, the\n",
    "#     network can predict negative values before it learns not to. We ensure that\n",
    "#     the network learns itself out of a bad region by penalizing negative\n",
    "#     consumption. We ensure that consumption is not negative by including a penalty\n",
    "#     term on c_orig_prime_1\n",
    "# c: is the corrected version c_all_orig_prime_1, in which all negative consumption\n",
    "#     values are set to ~0. If none of the consumption values are negative then\n",
    "#     c_orig_prime_1 == c_prime_1.\n",
    "c_orig = inc - a_all\n",
    "c = tf.maximum(c_orig, tf.ones_like(c_orig) * eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.B. Next period (t+1) <a id='nextperiod'></a>\n",
    "\n",
    "Now that we have calculated the current economic variables, we simulate one period forward. Since we have 4 possible futures---1 for each of the possible shocks that can realize---we simulate forward for each of the 4 states. Hence, we repeat each calculation 4 times. Below, we first calculate the aggregate variables for the beginning of the period. Then, we calculate the economy for shock $z=1$. The calculations for shock 2, 3, and 4 are analogous and will not be commented on.\n",
    "\n",
    "From the current period's savings $a_t$ we can calculate the next period's capital holdings $k_{t+1}^h$ and, consequently, aggregate capital $K_{t+1}$. Again, aggregate labor $L_{t+1}$ is 1 by construction.\n",
    "\n",
    "Then, like above, we calculate economic variables for each shock $z_{t+1} \\in \\{1, 2, 3, 4\\}$. That is, the new state `X'`$=[z_{t+1}, k_{t+1}^h]$ (together with the redundant extensions) is passed to the neural network to generate the agents' savings $a_{t+1}^h$. Then, we use `firm`, the `shocks`, and `wealth` to calculate the return on capital ($r_{t+1}$), the wages ($w_{t+1}$), and the agents' total income. Finally, consumption $c_{t+1}^h$ is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Next period\"\n",
    "  Knext = (1-delta)*K + (a1*((Inv/K)^((xsi-1)/xsi))+a2)*K;\n",
    "  bh_share_nezt is already defined\n",
    "\"\"\"\n",
    "\n",
    "# Today's savings become tomorrow's capital holding, but the first agent\n",
    "# is born without a capital endowment.\n",
    "k_prime = tf.concat([tf.zeros([m, 1]), a], axis=1)\n",
    "\n",
    "# Tomorrow's aggregate capital\n",
    "K_prime_orig = tf.reduce_sum(k_prime, axis=1, keepdims=True)\n",
    "K_prime = tf.maximum(K_prime_orig, tf.ones_like(K_prime_orig) * eps)\n",
    "\n",
    "# Tomorrow's labor\n",
    "l_prime = tf.tile(labor_endow, [m, 1])\n",
    "L_prime = tf.ones_like(K_prime)\n",
    "\n",
    "# Shock 1 ---------------------------------------------------------------------\n",
    "# 1) Get remaining parts of tomorrow's extended state\n",
    "# Exogenous shock\n",
    "\"\"\"TO DO: construct next period exogenous state Z_prime, the auxiliary variables, the full X next period, and policy functions\n",
    "Also: figure out if we can use this to construct recursive preferences\n",
    "construct loop for i in range(n_shocks):\"\"\"\n",
    "z_prime_1 = 0 * tf.ones_like(z)\n",
    "\n",
    "# TFP and depreciation\n",
    "tfp_prime_1, depr_prime_1 = shocks(z_prime_1, eta, delta)\n",
    "\n",
    "# Return on capital, wage and aggregate production\n",
    "r_prime_1, w_prime_1, Y_prime_1 = firm(K_prime, tfp_prime_1, alpha, depr_prime_1)\n",
    "R_prime_1 = r_prime_1 * tf.ones([1, A])\n",
    "W_prime_1 = w_prime_1 * tf.ones([1, A])\n",
    "\n",
    "# Distribution of financial wealth, labor income, and total income\n",
    "fw_prime_1, linc_prime_1, inc_prime_1 = wealth(k_prime, R_prime_1, l_prime, W_prime_1)\n",
    "\n",
    "# Tomorrow's state: Concatenate the parts together\n",
    "x_prime_1 = tf.concat([tf.expand_dims(z_prime_1, -1),\n",
    "                       tfp_prime_1,\n",
    "                       depr_prime_1,\n",
    "                       K_prime,\n",
    "                       L_prime,\n",
    "                       r_prime_1,\n",
    "                       w_prime_1,\n",
    "                       Y_prime_1,\n",
    "                       k_prime,\n",
    "                       fw_prime_1,\n",
    "                       linc_prime_1,\n",
    "                       inc_prime_1], axis=1)\n",
    "\n",
    "# 2) Get tomorrow's policy\n",
    "# Tomorrow's capital: capital holding at beginning of period and how much they save\n",
    "a_prime_1 = nn_predict(x_prime_1)\n",
    "a_prime_all_1 = tf.concat([a_prime_1, tf.zeros([m, 1])], axis=1)\n",
    "\n",
    "# 3) Tomorrow's consumption\n",
    "c_orig_prime_1 = inc_prime_1 - a_prime_all_1\n",
    "c_prime_1 = tf.maximum(c_orig_prime_1, tf.ones_like(c_orig_prime_1) * eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat for the remaining shocks\n",
    "Then, we do the same for the remaining shocks ($z = 2,3,4$). Nothing changes in terms of the math for the remaining shocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shock 2 ---------------------------------------------------------------------\n",
    "# 1) Get remaining parts of tomorrow's extended state\n",
    "# Exogenous shock\n",
    "z_prime_2 = 1 * tf.ones_like(z)\n",
    "\n",
    "# TFP and depreciation\n",
    "tfp_prime_2, depr_prime_2 = shocks(z_prime_2, eta, delta)\n",
    "\n",
    "# return on capital, wage and aggregate production\n",
    "r_prime_2, w_prime_2, Y_prime_2 = firm(K_prime, tfp_prime_2, alpha, depr_prime_2)\n",
    "R_prime_2 = r_prime_2 * tf.ones([1, A])\n",
    "W_prime_2 = w_prime_2 * tf.ones([1, A])\n",
    "\n",
    "# distribution of financial wealth, labor income, and total income\n",
    "fw_prime_2, linc_prime_2, inc_prime_2 = wealth(k_prime, R_prime_2, l_prime, W_prime_2)\n",
    "\n",
    "# Tomorrow's state: Concatenate the parts together\n",
    "x_prime_2 = tf.concat([tf.expand_dims(z_prime_2, -1),\n",
    "                       tfp_prime_2,\n",
    "                       depr_prime_2,\n",
    "                       K_prime,\n",
    "                       L_prime,\n",
    "                       r_prime_2,\n",
    "                       w_prime_2,\n",
    "                       Y_prime_2,\n",
    "                       k_prime,\n",
    "                       fw_prime_2,\n",
    "                       linc_prime_2,\n",
    "                       inc_prime_2], axis=1)\n",
    "\n",
    "# 2) Get tomorrow's policy\n",
    "a_prime_2 = nn_predict(x_prime_2)\n",
    "a_prime_all_2 = tf.concat([a_prime_2, tf.zeros([m, 1])], axis=1)\n",
    "\n",
    "# 3) Tomorrow's consumption\n",
    "c_orig_prime_2 = inc_prime_2 - a_prime_all_2\n",
    "c_prime_2= tf.maximum(c_orig_prime_2, tf.ones_like(c_orig_prime_2) * eps)\n",
    "\n",
    "# Shock 3 ---------------------------------------------------------------------\n",
    "# 1) Get remaining parts of tomorrow's extended state\n",
    "# Exogenous shock\n",
    "z_prime_3 = 2 * tf.ones_like(z)\n",
    "\n",
    "# TFP and depreciation\n",
    "tfp_prime_3, depr_prime_3 = shocks(z_prime_3, eta, delta)\n",
    "\n",
    "# return on capital, wage and aggregate production\n",
    "r_prime_3, w_prime_3, Y_prime_3 = firm(K_prime, tfp_prime_3, alpha, depr_prime_3)\n",
    "R_prime_3 = r_prime_3 * tf.ones([1, A])\n",
    "W_prime_3 = w_prime_3 * tf.ones([1, A])\n",
    "\n",
    "# distribution of financial wealth, labor income, and total income\n",
    "fw_prime_3, linc_prime_3, inc_prime_3 = wealth(k_prime, R_prime_3, l_prime, W_prime_3)\n",
    "\n",
    "# Tomorrow's state: Concatenate the parts together\n",
    "x_prime_3 = tf.concat([tf.expand_dims(z_prime_3, -1),\n",
    "                       tfp_prime_3,\n",
    "                       depr_prime_3,\n",
    "                       K_prime,\n",
    "                       L_prime,\n",
    "                       r_prime_3,\n",
    "                       w_prime_3,\n",
    "                       Y_prime_3,\n",
    "                       k_prime,\n",
    "                       fw_prime_3,\n",
    "                       linc_prime_3,\n",
    "                       inc_prime_3], axis=1)\n",
    "\n",
    "# 2) Get tomorrow's policy\n",
    "# Tomorrow's capital: capital holding at beginning of period and how much they save\n",
    "a_prime_3 = nn_predict(x_prime_3)\n",
    "a_prime_all_3 = tf.concat([a_prime_3, tf.zeros([m, 1])], axis=1)\n",
    "\n",
    "# 3) Tomorrow's consumption\n",
    "c_orig_prime_3 = inc_prime_3 - a_prime_all_3\n",
    "c_prime_3 = tf.maximum(c_orig_prime_3, tf.ones_like(c_orig_prime_3) * eps)\n",
    "\n",
    "# Shock 4 ---------------------------------------------------------------------\n",
    "# 1) Get remaining parts of tomorrow's extended state\n",
    "# Exogenous shock\n",
    "z_prime_4 = 3 * tf.ones_like(z)\n",
    "\n",
    "# TFP and depreciation\n",
    "tfp_prime_4, depr_prime_4 = shocks(z_prime_4, eta, delta)\n",
    "\n",
    "# return on capital, wage and aggregate production\n",
    "r_prime_4, w_prime_4, Y_prime_4 = firm(K_prime, tfp_prime_4, alpha, depr_prime_4)\n",
    "R_prime_4 = r_prime_4 * tf.ones([1, A])\n",
    "W_prime_4 = w_prime_4 * tf.ones([1, A])\n",
    "\n",
    "# distribution of financial wealth, labor income, and total income\n",
    "fw_prime_4, linc_prime_4, inc_prime_4 = wealth(k_prime, R_prime_4, l_prime, W_prime_4)\n",
    "\n",
    "# Tomorrow's state: Concatenate the parts together\n",
    "x_prime_4 = tf.concat([tf.expand_dims(z_prime_4, -1),\n",
    "                       tfp_prime_4,\n",
    "                       depr_prime_4,\n",
    "                       K_prime,\n",
    "                       L_prime,\n",
    "                       r_prime_4,\n",
    "                       w_prime_4,\n",
    "                       Y_prime_4,\n",
    "                       k_prime,\n",
    "                       fw_prime_4,\n",
    "                       linc_prime_4,\n",
    "                       inc_prime_4], axis=1)\n",
    "\n",
    "# 2) Get tomorrow's policy\n",
    "# Tomorrow's capital: capital holding at beginning of period and how much they save\n",
    "a_prime_4 = nn_predict(x_prime_4)\n",
    "a_prime_all_4 = tf.concat([a_prime_4, tf.zeros([m, 1])], axis=1)\n",
    "\n",
    "# 3) Tomorrow's consumption\n",
    "c_orig_prime_4 = inc_prime_4 - a_prime_all_4\n",
    "c_prime_4 = tf.maximum(c_orig_prime_4, tf.ones_like(c_orig_prime_4) * eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.C. Cost / Euler function <a id='cost'></a>\n",
    "\n",
    "#### tldr\n",
    "\n",
    "We train the neural network in an unsupervised fashion by approximating the equilibrium functions. The cost function is composed of the Euler equation, and the punishments for negative consumption and negative aggregate capital.\n",
    "\n",
    "***\n",
    "\n",
    "The final key ingredient is the cost function, which encodes the equilibrium functions.\n",
    "\n",
    "A loss function is needed to train a neural network. In supervised learning, the neural network's prediction is compared to the true value. The weights are updated in the direction that decreases the discripancy between the prediction and the truth. In _deep equilibrium nets_, we approximate all equilibrium functions directly. That is, we update the weights in the direction that minimizes these equilibrium functions. Since the equilibrium functions are approximately 0 in equilibrium, we do not require labeled data and can train in an unsupervised fashion.\n",
    "\n",
    "Our loss function has 3 components:\n",
    "\n",
    "  * the Euler equation,\n",
    "  * the punishments for negative consumption, and\n",
    "  * the punishments for negative aggregate capital.\n",
    "\n",
    "The relative errors in the Euler equation is given by:\n",
    "$$e_{\\text{REE}}^i(\\mathbf{x}_j) := \\frac{u^{\\prime -1}\\left(\\beta \\mathbf{E}_{z_j}{r(\\hat{\\mathbf{x}}_{j,+})u^{\\prime}(\\hat{c}^{i+1}(\\hat{\\mathbf{x}}_{j,+}))}\\right)}{\\hat{c}^i(\\mathbf{x}_j)}-1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Put our equilibrium conditions\n",
    "  err_bdgt_h = 1 - (W + (Div/mu) + b_h - Pf*(chi*Kss*(1-bn_shr_next)/mu))/c_h; % these are individual consumptions\n",
    "  err_bdgt_n = 1 - (W + b_n - Pf*(bn_shr_next*chi*Kss/(1-mu)))/c_n;\n",
    "  foc_stock = 1 - (beta*EEulerstock_future*(Evh_future^((alpha-rhoh)/(1-alpha))))/((c_h^(-rhoh))*Ps);\n",
    "  foc_bondh = 1 - (beta*EEulerbondh_future*(Evh_future^((alpha-rhoh)/(1-alpha))) + lambdah)/((c_h^(-rhoh))*Pf);\n",
    "  foc_bondn = 1 - (beta*EEulerbondn_future*(Evn_future^((alpha-rhon)/(1-alpha))) + lambdan)/((c_n^-rhon)*Pf);\n",
    "  foc_f = 1 - (beta*EEulerf_future*(Evh_future^((alpha-rhoh)/(1-alpha))))/((c_h^(-rhoh))*dIdKp);\n",
    "  \n",
    "  slack_bn = lambdan*(bn_shr_next - bn_shr_lb);    %mun_lw*bn_shr_next;\n",
    "  slack_bh = lambdah*(bn_shr_ub - bn_shr_next);    %mun_up*(1-bn_shr_next);\n",
    "  \n",
    "  ALSO: try weights for the functions\"\"\"\n",
    "\n",
    "# Prepare transitions to the next periods states. In this setting, there is a 25% chance\n",
    "# of ending up in any of the 4 states in Z. This has been hardcoded and need to be changed\n",
    "# to accomodate a different transition matrix.\n",
    "pi_trans_to1 = p_transition * tf.ones((m, A-1))\n",
    "pi_trans_to2 = p_transition * tf.ones((m, A-1))\n",
    "pi_trans_to3 = p_transition * tf.ones((m, A-1))\n",
    "pi_trans_to4 = p_transition * tf.ones((m, A-1))\n",
    "\n",
    "# Euler equation\n",
    "opt_euler = - 1 + (\n",
    "    (\n",
    "        (\n",
    "            beta * (\n",
    "                pi_trans_to1 * R_prime_1[:, 0:A-1] * c_prime_1[:, 1:A]**(-gamma) \n",
    "                + pi_trans_to2 * R_prime_2[:, 0:A-1] * c_prime_2[:, 1:A]**(-gamma) \n",
    "                + pi_trans_to3 * R_prime_3[:, 0:A-1] * c_prime_3[:, 1:A]**(-gamma) \n",
    "                + pi_trans_to4 * R_prime_4[:, 0:A-1] * c_prime_4[:, 1:A]**(-gamma)\n",
    "            )\n",
    "        ) ** (-1. / gamma)\n",
    "    ) / c[:, 0:A-1]\n",
    ")\n",
    "\n",
    "# Punishment for negative consumption (c)\n",
    "orig_cons = tf.concat([c_orig, c_orig_prime_1, c_orig_prime_2, c_orig_prime_3, c_orig_prime_4], axis=1)\n",
    "opt_punish_cons = (1./eps) * tf.maximum(-1 * orig_cons, tf.zeros_like(orig_cons))\n",
    "\n",
    "# Punishment for negative aggregate capital (K)\n",
    "opt_punish_ktot_prime = (1./eps) * tf.maximum(-K_prime_orig, tf.zeros_like(K_prime_orig))\n",
    "\n",
    "# Concatenate the 3 equilibrium functions\n",
    "combined_opt = [opt_euler, opt_punish_cons, opt_punish_ktot_prime]\n",
    "opt_predict = tf.concat(combined_opt, axis=1)\n",
    "\n",
    "# Define the \"correct\" outputs. For all equilibrium functions, the correct outputs is zero.\n",
    "opt_correct = tf.zeros_like(opt_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer\n",
    "\n",
    "Next, we chose an optimizer; i.e., the algorithm we use to perform gradient descent. We use [Adam](https://arxiv.org/abs/1412.6980), a favorite in deep learning research. Adam uses a parameter specific learning rate and momentum, which encourages gradient descent steps that occur in a consistent direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"all the same\"\"\"\n",
    "\n",
    "# Define the cost function\n",
    "cost = tf.losses.mean_squared_error(opt_correct, opt_predict)\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "# Clip the gradients to limit the extent of exploding gradients\n",
    "gvs = optimizer.compute_gradients(cost)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "\n",
    "# Define a training step\n",
    "train_step = optimizer.apply_gradients(capped_gvs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training <a id='training'></a>\n",
    "\n",
    "### tldr\n",
    "\n",
    "We iterate between simulating a dataset using the current neural network and training on this dataset.\n",
    "\n",
    "***\n",
    "\n",
    "In the final stage, we put everything together and train the neural network. \n",
    "\n",
    "In this section, we iterate between a simulation phase and a training phase. That is, we first simulate a dataset. We simulate a sequence of states ($[z, k]$) based on a random sequence of shocks. The states are computed using the current state of the neural network. We created the `simulate_episodes` helper function to do this. Then, in the training phase, we use the dataset to update our network parameters through multiple epochs. After completion of the training phase, we resimulate a dataset using the new network parameters and repeat.\n",
    "\n",
    "By computing the error directly after simulating a new dataset, we are able to evaluate our algorithms out-of-sample performance.\n",
    "\n",
    "First, we define the helper function `simulate_episodes` that simulates the training data used in an episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_episodes(sess, x_start, episode_length, print_flag=True):\n",
    "    \"\"\"Simulate an episode for a given starting point using the current\n",
    "       neural network state.\n",
    "\n",
    "    Args:\n",
    "        sess: Current tensorflow session,\n",
    "        x_start: Starting state to simulate forward from,\n",
    "        episode_length: Number of steps to simulate forward,\n",
    "        print_flag: Boolean that determines whether to print simulation stats.\n",
    "\n",
    "    Returns:\n",
    "        X_episodes: Tensor of states [z, k] to train on (training set).\n",
    "    \"\"\"\n",
    "    time_start = datetime.now()\n",
    "    if print_flag:\n",
    "        print('Start simulating {} periods.'.format(episode_length))\n",
    "    dim_state = np.shape(x_start)[1]\n",
    "\n",
    "    X_episodes = np.zeros([episode_length, dim_state])\n",
    "    X_episodes[0, :] = x_start\n",
    "    X_old = x_start\n",
    "\n",
    "    # Generate a sequence of random shocks\n",
    "    rand_num = np.random.rand(episode_length, 1)\n",
    "\n",
    "    for t in range(1, episode_length):\n",
    "        z = int(X_old[0, 0])  # Current period's shock\n",
    "\"\"\"TO DO: change simulation part\"\"\" \n",
    "        # Determine which state we will be in in the next period based on\n",
    "        # the shock and generate the corresponding state (x_prime)\n",
    "        if rand_num[t - 1] <= pi_np[z, 0]:\n",
    "            X_new = sess.run(x_prime_1, feed_dict={X: X_old})\n",
    "        elif rand_num[t - 1] <= pi_np[z, 0] + pi_np[z, 1]:\n",
    "            X_new = sess.run(x_prime_2, feed_dict={X: X_old})\n",
    "        elif rand_num[t - 1] <= pi_np[z, 0] + pi_np[z, 1] + pi_np[z, 2]:\n",
    "            X_new = sess.run(x_prime_3, feed_dict={X: X_old})\n",
    "        else:\n",
    "            X_new = sess.run(x_prime_4, feed_dict={X: X_old})\n",
    "        \n",
    "        # Append it to the dataset\n",
    "        X_episodes[t, :] = X_new\n",
    "        X_old = X_new\n",
    "\n",
    "    time_end = datetime.now()\n",
    "    time_diff = time_end - time_start\n",
    "    if print_flag:\n",
    "        print('Finished simulation. Time for simulation: {}.'.format(time_diff))\n",
    "\n",
    "    return X_episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The true analytic solution\n",
    "This model can be solved analytically.\n",
    "Therefore, additionally to the relative errors in the Euler equations, we can compare the solution learned by the neural network directly to the true solution.\n",
    "The true policy is given by\n",
    "\\begin{align}\n",
    "\\mathbf{a}^{\\text{analytic}}_t=\n",
    "\\beta\n",
    "\\begin{bmatrix}\n",
    "\\frac{1-\\beta^{A-1}}{1-\\beta^{A}} w_t \\\\\n",
    "\\frac{1-\\beta^{A-2}}{1-\\beta^{A-1}} r_t k^{1}_t \\\\\n",
    "\\frac{1-\\beta^{A-3}}{1-\\beta^{A-2}} r_t k^{2}_t \\\\\n",
    "\\dots \\\\\n",
    "\\frac{1-\\beta^{1}}{1-\\beta^2} r_t k^{A-2}_t \\\\\n",
    "\\end{bmatrix}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_vec = beta_np * (1 - beta_np ** (A - 1 - np.arange(A-1))) / (1 - beta_np ** (A - np.arange(A-1)))\n",
    "beta_vec = tf.constant(np.expand_dims(beta_vec, 0), dtype=tf.float32)\n",
    "a_analytic = inc[:, : -1] * beta_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the _deep equilibrium net_\n",
    "\n",
    "Now we can begin training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TO DO: change plots and number of shocks\"\"\"\n",
    "\n",
    "# Helper variables for plotting\n",
    "all_ages = np.arange(1, A+1)\n",
    "ages = np.arange(1, A)\n",
    "\n",
    "# Initialize tensorflow session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize interactive plotting\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3, 3, figsize=(18, 18))\n",
    "plt.ion()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "# Generate a random starting point\n",
    "if data_path:\n",
    "    X_data_train = np.load(data_path)\n",
    "    print('Loaded initial data from ' + data_path)\n",
    "    start_episode = int(re.search('_(.*).npy', data_path).group(1))\n",
    "else:\n",
    "    X_data_train = np.random.rand(1, num_input_nodes)\n",
    "    X_data_train[:, 0] = (X_data_train[:, 0] > 0.5)\n",
    "    X_data_train[:, 1:] = X_data_train[:, 1:] + 0.1\n",
    "    assert np.min(np.sum(X_data_train[:, 1:], axis=1, keepdims=True) > 0) == True, 'Starting point has negative aggregate capital (K)!'\n",
    "    print('Calculated a valid starting point')\n",
    "    start_episode = 0\n",
    "\n",
    "train_seed = 0\n",
    "\n",
    "cost_store, mov_ave_cost_store = [], []\n",
    "\n",
    "time_start = datetime.now()\n",
    "print('start time: {}'.format(time_start))\n",
    "\n",
    "# Initialize the random variables (neural network weights)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Initialize saver to save and load previous sessions\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "if sess_path is not None:\n",
    "    saver.restore(sess, sess_path)\n",
    "            \n",
    "for episode in range(start_episode, num_episodes):\n",
    "    # Simulate data: every episode uses a new training dataset generated on the current\n",
    "    # iteration's neural network parameters.\n",
    "    X_episodes = simulate_episodes(sess, X_data_train, len_episodes, print_flag=(episode==0))\n",
    "    X_data_train = X_episodes[-1, :].reshape([1, -1])\n",
    "    k_dist_mean = np.mean(X_episodes[:, 8 : 8 + A], axis=0)\n",
    "    k_dist_min = np.min(X_episodes[:, 8 : 8 + A], axis=0)\n",
    "    k_dist_max = np.max(X_episodes[:, 8 : 8 + A], axis=0)\n",
    "    \n",
    "    ee_error = np.zeros((1, num_agents-1))\n",
    "    max_ee = np.zeros((1, num_agents-1))\n",
    "\n",
    "    for epoch in range(epochs_per_episode):\n",
    "        # Every epoch is one full pass through the dataset. We train multiple passes on \n",
    "        # one training set before we resimulate a new dataset.\n",
    "        train_seed += 1\n",
    "        minibatch_cost = 0\n",
    "\n",
    "        # Mini-batch the simulated data\n",
    "        minibatches = random_mini_batches(X_episodes, minibatch_size, train_seed)\n",
    "\n",
    "        for minibatch_X in minibatches:\n",
    "            # Run optimization; i.e., determine the cost of each mini-batch.\n",
    "            minibatch_cost += sess.run(cost, feed_dict={X: minibatch_X}) / num_minibatches\n",
    "            if epoch == 0:\n",
    "                # For the first epoch, save the mean and max euler errors for plotting\n",
    "                # This way, the errors are calculated out-of-sample.\n",
    "                opt_euler_ = np.abs(sess.run(opt_euler, feed_dict={X: minibatch_X}))\n",
    "                ee_error += np.mean(opt_euler_, axis=0) / num_minibatches\n",
    "                mb_max_ee = np.max(opt_euler_, axis=0, keepdims=True)\n",
    "                max_ee = np.maximum(max_ee, mb_max_ee)\n",
    "\n",
    "        if epoch == 0:\n",
    "            # Record the cost and moving average of the cost at the beginning of each\n",
    "            # episode to track learning progress.\n",
    "            cost_store.append(minibatch_cost)\n",
    "            mov_ave_cost_store.append(np.mean(cost_store[-100:]))\n",
    "\n",
    "        for minibatch_X in minibatches:\n",
    "            # Take a mini-batch gradient descent training step. That is, update the\n",
    "            # weights for one mini-batch.\n",
    "            sess.run(train_step, feed_dict={X: minibatch_X})\n",
    "            \n",
    "    if episode % 20 == 0:\n",
    "        # Plot\n",
    "        # Plot the loss function\n",
    "        ax1.clear()\n",
    "        line_cost = ax1.plot(np.log10(cost_store), label='Cost')\n",
    "        line_mov_ave = ax1.plot(np.log10(mov_ave_cost_store), label='Moving average')\n",
    "        ax1.set_xlabel('Episodes')\n",
    "        ax1.set_ylabel('Cost [log10]')\n",
    "        ax1.legend(loc='upper right')\n",
    "\n",
    "        # Plot the relative errors in the Euler equation\n",
    "        ax2.clear()\n",
    "        ee_mean_cost = ax2.plot(ages, np.log10(ee_error).ravel(), 'k-', label='mean')\n",
    "        ee_max_cost = ax2.plot(ages, np.log10(max_ee).ravel(), '--', label='max')\n",
    "        ax2.set_xlabel('Age')\n",
    "        ax2.set_ylabel('Rel EE [log10]')\n",
    "        ax2.set_xticks(ages)\n",
    "        ax2.legend()\n",
    "\n",
    "        # Plot the capital distribution\n",
    "        ax3.clear()\n",
    "        k_mean_cost = ax3.plot(all_ages, k_dist_mean, 'k-')\n",
    "        k_min_cost = ax3.plot(all_ages, k_dist_min, 'k--')\n",
    "        k_max_cost = ax3.plot(all_ages, k_dist_max, 'k--')\n",
    "        ax3.set_xlabel('Age')\n",
    "        ax3.set_ylabel('capital (k)')\n",
    "        ax3.set_xticks(all_ages)\n",
    "        \n",
    "        # =======================================================================================\n",
    "        # Sample 50 states and compare the neural network's prediction to the analytical solution\n",
    "        pick = np.random.randint(len_episodes, size=50)\n",
    "        random_states = X_episodes[pick, :]\n",
    "\n",
    "        # Sort the states by the exogenous shock\n",
    "        random_states_1 = random_states[random_states[:, 0] == 0]\n",
    "        random_states_2 = random_states[random_states[:, 0] == 1]\n",
    "        random_states_3 = random_states[random_states[:, 0] == 2]\n",
    "        random_states_4 = random_states[random_states[:, 0] == 3]\n",
    "\n",
    "        # Get corresponding capital distribution for plots\n",
    "        random_k_1 = random_states_1[:, 8 : 8 + A]\n",
    "        random_k_2 = random_states_2[:, 8 : 8 + A]\n",
    "        random_k_3 = random_states_3[:, 8 : 8 + A]\n",
    "        random_k_4 = random_states_4[:, 8 : 8 + A]\n",
    "\n",
    "        # Generate a prediction using the neural network\n",
    "        nn_pred_1 = sess.run(a, feed_dict={X: random_states_1})\n",
    "        nn_pred_2 = sess.run(a, feed_dict={X: random_states_2})\n",
    "        nn_pred_3 = sess.run(a, feed_dict={X: random_states_3})\n",
    "        nn_pred_4 = sess.run(a, feed_dict={X: random_states_4})\n",
    "\n",
    "        # Calculate the analytical solution\n",
    "        true_pol_1 = sess.run(a_analytic, feed_dict={X: random_states_1})\n",
    "        true_pol_2 = sess.run(a_analytic, feed_dict={X: random_states_2})\n",
    "        true_pol_3 = sess.run(a_analytic, feed_dict={X: random_states_3})\n",
    "        true_pol_4 = sess.run(a_analytic, feed_dict={X: random_states_4})\n",
    "\n",
    "        ax_list = [ax4, ax5, ax6, ax7, ax8]\n",
    "        # Plot both\n",
    "        for i in range(A - 1):\n",
    "            ax = ax_list[i]\n",
    "            \n",
    "            ax.clear()\n",
    "            # Plot the true solution with a circle\n",
    "            ax.plot(random_k_1[:, i], true_pol_1[:, i], 'ro', mfc='none', alpha=0.5, markersize=6, label='analytic')\n",
    "            ax.plot(random_k_2[:, i], true_pol_2[:, i], 'bo', mfc='none', alpha=0.5, markersize=6)\n",
    "            ax.plot(random_k_3[:, i], true_pol_3[:, i], 'go', mfc='none', alpha=0.5, markersize=6)\n",
    "            ax.plot(random_k_4[:, i], true_pol_4[:, i], 'yo', mfc='none', alpha=0.5, markersize=6)\n",
    "            # Plot the prediction of the neural net\n",
    "            ax.plot(random_k_1[:, i], nn_pred_1[:, i], 'r*', markersize=2, label='DEQN')\n",
    "            ax.plot(random_k_2[:, i], nn_pred_2[:, i], 'b*', markersize=2)\n",
    "            ax.plot(random_k_3[:, i], nn_pred_3[:, i], 'g*', markersize=2)\n",
    "            ax.plot(random_k_4[:, i], nn_pred_4[:, i], 'y*', markersize=2)\n",
    "            ax.set_title('Agent {}'.format(i+1))\n",
    "            ax.set_xlabel(r'$k_t$')\n",
    "            ax.set_ylabel(r'$a_t$')\n",
    "            ax.legend()\n",
    "\n",
    "        ax9.axis('off')\n",
    "        fig.canvas.draw()\n",
    "        #========================================================================================\n",
    "\n",
    "    # Print cost and time log\n",
    "    print('Episode {}: log10(Cost): {:.4f}; time: {}; time since start: {}'.format(episode, \n",
    "                                                                                   np.log10(cost_store[-1]), \n",
    "                                                                                   datetime.now().time(), \n",
    "                                                                                   datetime.now() - time_start))\n",
    "\n",
    "    if episode % 100 == 0:\n",
    "        # Save the tensorflow session\n",
    "        saver.save(sess, './output/sess_{}.ckpt'.format(episode))\n",
    "        # Save the starting point\n",
    "        np.save('./output/data_{}.npy'.format(episode), X_data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
